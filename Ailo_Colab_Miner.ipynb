{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "#@title üöÄ Ailo Colab Miner - One Click Mining!\n#@markdown ### Instructions:\n#@markdown 1. Runtime > Change runtime type > **T4 GPU**\n#@markdown 2. Enter your wallet address below\n#@markdown 3. Press **‚ñ∂Ô∏è Play** - that's it!\n#@markdown ---\n\nWALLET = \"\"  #@param {type:\"string\"}\n\n# ===== DO NOT EDIT BELOW =====\nimport subprocess, sys\nsubprocess.run([sys.executable, '-m', 'pip', 'install', 'torch', '--index-url', 'https://download.pytorch.org/whl/cu118', '-q'], capture_output=True)\nsubprocess.run([sys.executable, '-m', 'pip', 'install', 'aiohttp', 'requests', '-q'], capture_output=True)\n\nimport torch, torch.nn as nn, numpy as np, requests, aiohttp, asyncio, time, base64, gzip, gc, os\n\nAPI, SERVER, VER = \"https://ailo.site/api\", \"https://ailo.site\", \"1.8.0-colab\"\nMAX_LOSS_FOR_SUBMIT = 2.8  # STRICT: Don't submit if loss is higher than global model\n\nif not torch.cuda.is_available():\n    print(\"‚ùå GPU not enabled! Go to: Runtime > Change runtime type > T4 GPU\")\n    raise SystemExit\n\nif len(WALLET) < 40:\n    print(\"‚ùå Enter your wallet address above! Get one at: https://ailo.site/wallet.html\")\n    raise SystemExit\n\nprint(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)} | VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\nprint(f\"‚úÖ Wallet: {WALLET[:12]}...\")\n\nclass AILO1B(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.emb = nn.Embedding(50257, 1600)\n        self.pos = nn.Parameter(torch.zeros(1, 512, 1600))\n        self.tf = nn.TransformerEncoder(nn.TransformerEncoderLayer(1600, 25, 6400, 0.1, batch_first=True), 24)\n        self.out = nn.Linear(1600, 50257)\n    def forward(self, x):\n        return self.out(self.tf(self.emb(x) * 40 + self.pos[:, :x.size(1)]))\n\nclass Trainer:\n    def __init__(self):\n        self.dev = torch.device('cuda')\n        self.m = None; self.opt = None; self.steps = 0; self.acc = 0\n        self.best_loss = float('inf'); self.local_version = 0\n        self.saved_grads = None\n        self.synced = False  # CRITICAL: Track if we synced with global model\n    \n    def init(self):\n        print(\"üß† Loading AILO-1B (899M params)...\")\n        gc.collect(); torch.cuda.empty_cache()\n        self.m = AILO1B().half().to(self.dev)\n        print(f\"   ‚úÖ Ready! GPU Memory: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n        self.opt = torch.optim.SGD(self.m.parameters(), lr=0.001, momentum=0.9)\n        self.crit = nn.CrossEntropyLoss()\n    \n    def sync_with_global(self):\n        try:\n            print(\"üîÑ Syncing with global model...\")\n            r = requests.get(f\"{SERVER}/api/model/weights\", timeout=30)\n            if r.status_code != 200: \n                print(\"   ‚ö†Ô∏è No global model available\")\n                return False\n            data = r.json()\n            if data.get('hasCheckpoint', False):\n                server_loss = data.get('bestCheckpointLoss', 999)\n                print(f\"   üì• Downloading checkpoint (loss: {server_loss})...\")\n                cr = requests.get(f\"{SERVER}/api/model/checkpoint\", timeout=60)\n                if cr.status_code == 200:\n                    w = np.frombuffer(cr.content, dtype=np.float16).astype(np.float32)\n                    with torch.no_grad():\n                        exp = self.m.out.weight.numel()\n                        if len(w) >= exp:\n                            self.m.out.weight.data = torch.from_numpy(w[:exp]).reshape_as(self.m.out.weight).half().to(self.dev)\n                            self.synced = True\n                            self.best_loss = float(server_loss) if server_loss != 'N/A' else 2.8\n                            print(f\"   ‚úÖ Loaded {exp:,} weights (target loss: {self.best_loss:.4f})\")\n                    return True\n            return False\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è Sync failed: {e}\")\n            return False\n    \n    def upload_checkpoint(self, wallet, loss, epoch):\n        try:\n            with torch.no_grad():\n                w = self.m.out.weight.data.cpu().half().numpy().tobytes()\n                w64 = base64.b64encode(w).decode()\n            r = requests.post(f\"{SERVER}/api/model/checkpoint\", json={'wallet': wallet, 'weights': w64, 'loss': loss, 'epoch': epoch}, timeout=60)\n            if r.status_code == 200 and r.json().get('success'):\n                print(f\"   üì¶ Checkpoint uploaded!\")\n        except: pass\n    \n    def batch(self, w):\n        try:\n            r = requests.get(f\"{API}/cuda/training-data\", params={'batchSize': 1, 'wallet': w}, timeout=10)\n            if r.ok:\n                t = r.json().get('articles', [''])[0]\n                if len(t) >= 33:  # CRITICAL: Only use valid data\n                    tk = [ord(c) % 50257 for c in t[:33]]\n                    return torch.tensor([tk[:32]]), torch.tensor([tk[1:33]])\n        except: pass\n        # NO FALLBACK TO RANDOM - return None to skip this batch\n        return None, None\n    \n    def step(self, x, y):\n        if x is None: return None  # Skip if no valid data\n        self.m.train()\n        x, y = x.to(self.dev), y.to(self.dev)\n        with torch.cuda.amp.autocast():\n            loss = self.crit(self.m(x).view(-1, 50257), y.view(-1)) / 16\n        loss.backward()\n        self.acc += 1\n        if self.acc >= 16:\n            nn.utils.clip_grad_norm_(self.m.parameters(), 1.0)\n            g = self.m.out.weight.grad\n            if g is not None:\n                self.saved_grads = g.clone().cpu()\n            self.opt.step(); self.opt.zero_grad(set_to_none=True); self.acc = 0\n        self.steps += 1\n        l = loss.item() * 16\n        if l < self.best_loss and not np.isnan(l): self.best_loss = l\n        if self.steps % 50 == 0: gc.collect(); torch.cuda.empty_cache()\n        return l\n    \n    def grads(self):\n        g = self.saved_grads\n        if g is None: \n            print(\"   ‚ö†Ô∏è No gradients yet\")\n            return None\n        gc.collect()\n        flat = g.float().flatten()\n        sample = flat[::10]\n        comp = gzip.compress(sample.half().numpy().tobytes(), 4)\n        return base64.b64encode(comp).decode()\n\nasync def hb(w, tps):\n    try:\n        async with aiohttp.ClientSession() as s:\n            await s.post(f\"{API}/cuda/register\", json={'wallet': w, 'clientVersion': VER, 'deviceInfo': {'gpu_name': 'T4-Colab', 'vram_gb': 15, 'hashrate': tps}})\n    except: pass\n\nasync def submit(w, g, s, l):\n    try:\n        async with aiohttp.ClientSession() as ss:\n            async with ss.post(f\"{API}/cuda/submit\", json={'wallet': w, 'gradients': g, 'epoch': s, 'loss': l, 'gpu': 'T4-Colab'}) as r:\n                if r.status == 200: return (await r.json()).get('reward', 0)\n    except: pass\n    return 0\n\nasync def run():\n    print(\"=\" * 50)\n    print(f\"  üöÄ AILO-1B Colab Miner v{VER}\")\n    print(\"=\" * 50)\n    \n    await hb(WALLET, 0)\n    t = Trainer(); t.init()\n    \n    # CRITICAL: Must sync before training!\n    if not t.sync_with_global():\n        print(\"\\n‚ö†Ô∏è Could not sync with global model!\")\n        print(\"   Will train but NOT submit gradients until synced.\")\n    \n    print(\"\\n‚õèÔ∏è MINING STARTED!\")\n    print(f\"üìä Dashboard: https://ailo.site/dashboard.html?wallet={WALLET[:12]}\\n\")\n    \n    rew, last_s, last_h, tps = 0.0, time.time(), time.time(), 0.0\n    skipped_batches = 0\n    \n    try:\n        while True:\n            t0 = time.time()\n            x, y = t.batch(WALLET)\n            if x is None:\n                skipped_batches += 1\n                if skipped_batches % 10 == 0:\n                    print(f\"‚è≠Ô∏è Skipped {skipped_batches} batches (no valid data)\")\n                await asyncio.sleep(0.5)\n                continue\n            \n            loss = t.step(x, y)\n            if loss is None: continue\n            \n            tps = 32 / (time.time() - t0 + 0.001)\n            \n            if time.time() - last_h >= 10: await hb(WALLET, tps); last_h = time.time()\n            if t.steps % 25 == 0: print(f\"Step {t.steps} | Loss: {loss:.4f} | Best: {t.best_loss:.4f} | {tps:.0f} tok/s | üí∞ {rew:.4f} ALC\")\n            \n            if time.time() - last_s >= 300:\n                gc.collect(); torch.cuda.empty_cache()\n                g = t.grads()\n                \n                # CRITICAL: Only submit if synced AND loss is good\n                if g and t.synced and t.best_loss < MAX_LOSS_FOR_SUBMIT and not np.isnan(t.best_loss):\n                    print(f\"\\nüì§ Submitting gradients (loss: {t.best_loss:.4f})...\")\n                    r = await submit(WALLET, g, t.steps, t.best_loss); rew += r\n                    print(f\"üí∞ +{r:.4f} ALC (Total: {rew:.4f})\")\n                    if t.best_loss < 2.5: t.upload_checkpoint(WALLET, t.best_loss, t.steps)\n                elif not t.synced:\n                    print(f\"\\n‚è≥ Not synced with global model - training locally...\")\n                elif g:\n                    print(f\"\\n‚è≥ Loss too high ({t.best_loss:.4f} > {MAX_LOSS_FOR_SUBMIT}) - training more...\")\n                else:\n                    print(\"\\n‚è≠Ô∏è No gradients yet\")\n                \n                t.sync_with_global()\n                last_s = time.time()\n                print()\n                \n    except KeyboardInterrupt: print(f\"\\n‚èπÔ∏è Stopped. Total earned: {rew:.4f} ALC\")\n\nawait run()"
            ],
            "metadata": {
                "id": "ailo_miner",
                "cellView": "form"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}