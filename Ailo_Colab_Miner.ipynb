{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üöÄ Ailo Colab Miner (AILO-1B)\n\n1. Runtime > Change runtime type > T4 GPU\n2. Enter wallet below\n3. Runtime > Run all"
            ],
            "metadata": {
                "id": "h"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ‚öôÔ∏è 1. Setup\n!pip install torch --index-url https://download.pytorch.org/whl/cu118 -q\n!pip install aiohttp requests -q\nimport gc; gc.collect()\nimport torch\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)} | VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\nelse:\n    print(\"‚ùå Enable GPU!\")"
            ],
            "metadata": {
                "id": "s"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üîë 2. Wallet\nWALLET = \"\"  #@param {type:\"string\"}\nprint(f\"‚úÖ {WALLET[:12]}...\" if len(WALLET)>=40 else \"‚ùå Enter wallet!\")"
            ],
            "metadata": {
                "id": "w"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üß† 3. Model & Training\nimport torch, torch.nn as nn, numpy as np, requests, aiohttp, asyncio, time, base64, gzip, gc\n\nAPI=\"https://ailo.site/api\"\nVER=\"1.4.0-colab\"\n\nclass AILO1B(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.emb=nn.Embedding(50257,1600)\n        self.pos=nn.Parameter(torch.zeros(1,512,1600))\n        self.tf=nn.TransformerEncoder(nn.TransformerEncoderLayer(1600,25,6400,0.1,batch_first=True),24)\n        self.out=nn.Linear(1600,50257)\n    def forward(self,x):\n        return self.out(self.tf(self.emb(x)*40+self.pos[:,:x.size(1)]))\n\nclass Trainer:\n    def __init__(self):\n        self.dev=torch.device('cuda')\n        self.m=None; self.opt=None; self.steps=0; self.acc=0\n    \n    def init(self):\n        print(\"üß† Loading AILO-1B...\")\n        gc.collect(); torch.cuda.empty_cache()\n        self.m=AILO1B().half().to(self.dev)\n        print(f\"   {sum(p.numel() for p in self.m.parameters()):,} params | GPU: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n        self.opt=torch.optim.SGD(self.m.parameters(),lr=0.001,momentum=0.9)\n        self.crit=nn.CrossEntropyLoss()\n        print(\"   ‚úÖ Ready!\")\n    \n    def batch(self,w):\n        try:\n            r=requests.get(f\"{API}/cuda/training-data\",params={'batchSize':1,'wallet':w},timeout=10)\n            if r.ok:\n                t=r.json().get('articles',[''])[0]\n                tk=[ord(c)%50257 for c in t[:33]]\n                tk+=[0]*(33-len(tk))\n                return torch.tensor([tk[:32]]),torch.tensor([tk[1:33]])\n        except:pass\n        return torch.randint(0,50257,(1,32)),torch.randint(0,50257,(1,32))\n    \n    def step(self,x,y):\n        self.m.train()\n        x,y=x.to(self.dev),y.to(self.dev)\n        with torch.cuda.amp.autocast():\n            loss=self.crit(self.m(x).view(-1,50257),y.view(-1))/16\n        loss.backward()\n        self.acc+=1\n        if self.acc>=16:\n            nn.utils.clip_grad_norm_(self.m.parameters(),1.0)\n            self.opt.step(); self.opt.zero_grad(set_to_none=True); self.acc=0\n        self.steps+=1\n        if self.steps%50==0: gc.collect(); torch.cuda.empty_cache()\n        return loss.item()*16\n    \n    def grads(self):\n        # Only sample gradients from output layer to save RAM!\n        # Output layer is the most important for learning\n        g=self.m.out.weight.grad\n        if g is None: return None\n        gc.collect()\n        # Sample 10% of gradients to fit in RAM\n        flat=g.cpu().float().flatten()\n        sample=flat[::10]  # Take every 10th value\n        del flat; gc.collect()\n        comp=gzip.compress(sample.half().numpy().tobytes(),4)\n        del sample; gc.collect()\n        return base64.b64encode(comp).decode()\n\nprint(\"‚úÖ Ready\")"
            ],
            "metadata": {
                "id": "m"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üöÄ 4. Mine!\n\nasync def hb(w,tps):\n    try:\n        async with aiohttp.ClientSession() as s:\n            await s.post(f\"{API}/cuda/register\",json={'wallet':w,'clientVersion':VER,'deviceInfo':{'gpu_name':'T4-Colab','vram_gb':15,'hashrate':tps}})\n            await s.post(f\"{API}/ping\",json={'wallet':w,'status':'training','hashrate':f\"{tps:.0f} Tok/s\"})\n    except:pass\n\nasync def submit(w,g,s,l):\n    try:\n        async with aiohttp.ClientSession() as ss:\n            async with ss.post(f\"{API}/cuda/submit\",json={'wallet':w,'gradients':g,'epoch':s,'loss':l,'gpu':'T4-Colab'}) as r:\n                if r.status==200: return (await r.json()).get('reward',0)\n    except:pass\n    return 0\n\nasync def run():\n    if len(WALLET)<40: print(\"‚ùå Set wallet!\"); return\n    print(\"=\"*40+f\"\\n  AILO-1B Colab v{VER}\\n\"+\"=\"*40)\n    await hb(WALLET,0)\n    t=Trainer(); t.init()\n    print(\"\\n‚õèÔ∏è MINING!\\n\")\n    rew,last_s,last_h,tps=0.0,time.time(),time.time(),0.0\n    try:\n        while True:\n            t0=time.time()\n            x,y=t.batch(WALLET)\n            loss=t.step(x,y)\n            tps=32/(time.time()-t0+0.001)\n            if time.time()-last_h>=10: await hb(WALLET,tps); last_h=time.time()\n            if t.steps%25==0: print(f\"Step {t.steps} | Loss: {loss:.4f} | {tps:.0f} tok/s | GPU: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n            if time.time()-last_s>=300:\n                print(\"\\nüì§ Submitting...\")\n                gc.collect(); torch.cuda.empty_cache()  # Clean before grad extraction\n                g=t.grads()\n                if g:\n                    r=await submit(WALLET,g,t.steps,loss); rew+=r\n                    print(f\"üí∞ +{r:.4f} ALC (Total: {rew:.4f})\\n\")\n                gc.collect()  # Clean after\n                last_s=time.time()\n    except KeyboardInterrupt: print(f\"\\n‚èπÔ∏è Total: {rew:.4f} ALC\")\n\nawait run()"
            ],
            "metadata": {
                "id": "r"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}