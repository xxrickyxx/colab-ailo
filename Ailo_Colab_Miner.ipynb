{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "code",
            "source": [
                "#@title ðŸš€ Ailo Colab Miner - One Click Mining!\n#@markdown ### Instructions:\n#@markdown 1. Runtime > Change runtime type > **T4 GPU**\n#@markdown 2. Enter your wallet address below\n#@markdown 3. Press **â–¶ï¸ Play** - that's it!\n#@markdown ---\n\nWALLET = \"\"  #@param {type:\"string\"}\n\n# ===== DO NOT EDIT BELOW =====\nimport subprocess, sys\nsubprocess.run([sys.executable, '-m', 'pip', 'install', 'torch', '--index-url', 'https://download.pytorch.org/whl/cu118', '-q'], capture_output=True)\nsubprocess.run([sys.executable, '-m', 'pip', 'install', 'aiohttp', 'requests', '-q'], capture_output=True)\n\nimport torch, torch.nn as nn, numpy as np, requests, aiohttp, asyncio, time, base64, gzip, gc, os\n\nAPI, SERVER, VER = \"https://ailo.site/api\", \"https://ailo.site\", \"1.7.1-colab\"\n\nif not torch.cuda.is_available():\n    print(\"âŒ GPU not enabled! Go to: Runtime > Change runtime type > T4 GPU\")\n    raise SystemExit\n\nif len(WALLET) < 40:\n    print(\"âŒ Enter your wallet address above! Get one at: https://ailo.site/wallet.html\")\n    raise SystemExit\n\nprint(f\"âœ… GPU: {torch.cuda.get_device_name(0)} | VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\nprint(f\"âœ… Wallet: {WALLET[:12]}...\")\n\nclass AILO1B(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.emb = nn.Embedding(50257, 1600)\n        self.pos = nn.Parameter(torch.zeros(1, 512, 1600))\n        self.tf = nn.TransformerEncoder(nn.TransformerEncoderLayer(1600, 25, 6400, 0.1, batch_first=True), 24)\n        self.out = nn.Linear(1600, 50257)\n    def forward(self, x):\n        return self.out(self.tf(self.emb(x) * 40 + self.pos[:, :x.size(1)]))\n\nclass Trainer:\n    def __init__(self):\n        self.dev = torch.device('cuda')\n        self.m = None; self.opt = None; self.steps = 0; self.acc = 0\n        self.best_loss = float('inf'); self.local_version = 0\n        self.saved_grads = None  # Store gradients for submission\n    \n    def init(self):\n        print(\"ðŸ§  Loading AILO-1B (899M params)...\")\n        gc.collect(); torch.cuda.empty_cache()\n        self.m = AILO1B().half().to(self.dev)\n        print(f\"   âœ… Ready! GPU Memory: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n        self.opt = torch.optim.SGD(self.m.parameters(), lr=0.001, momentum=0.9)\n        self.crit = nn.CrossEntropyLoss()\n    \n    def sync_with_global(self):\n        try:\n            print(\"ðŸ”„ Syncing with global model...\")\n            r = requests.get(f\"{SERVER}/api/model/weights\", timeout=30)\n            if r.status_code != 200: return False\n            data = r.json()\n            if data.get('hasCheckpoint', False):\n                print(f\"   ðŸ“¥ Downloading checkpoint (loss: {data.get('bestCheckpointLoss', 'N/A')})...\")\n                cr = requests.get(f\"{SERVER}/api/model/checkpoint\", timeout=60)\n                if cr.status_code == 200:\n                    w = np.frombuffer(cr.content, dtype=np.float16).astype(np.float32)\n                    with torch.no_grad():\n                        exp = self.m.out.weight.numel()\n                        if len(w) >= exp:\n                            self.m.out.weight.data = torch.from_numpy(w[:exp]).reshape_as(self.m.out.weight).half().to(self.dev)\n                            print(f\"   âœ… Loaded {exp:,} weights\")\n                    return True\n            return False\n        except Exception as e:\n            print(f\"   âš ï¸ Sync failed: {e}\")\n            return False\n    \n    def upload_checkpoint(self, wallet, loss, epoch):\n        try:\n            with torch.no_grad():\n                w = self.m.out.weight.data.cpu().half().numpy().tobytes()\n                w64 = base64.b64encode(w).decode()\n            r = requests.post(f\"{SERVER}/api/model/checkpoint\", json={'wallet': wallet, 'weights': w64, 'loss': loss, 'epoch': epoch}, timeout=60)\n            if r.status_code == 200 and r.json().get('success'):\n                print(f\"   ðŸ“¦ Checkpoint uploaded!\")\n        except: pass\n    \n    def batch(self, w):\n        try:\n            r = requests.get(f\"{API}/cuda/training-data\", params={'batchSize': 1, 'wallet': w}, timeout=10)\n            if r.ok:\n                t = r.json().get('articles', [''])[0]\n                tk = [ord(c) % 50257 for c in t[:33]]\n                tk += [0] * (33 - len(tk))\n                return torch.tensor([tk[:32]]), torch.tensor([tk[1:33]])\n        except: pass\n        return torch.randint(0, 50257, (1, 32)), torch.randint(0, 50257, (1, 32))\n    \n    def step(self, x, y):\n        self.m.train()\n        x, y = x.to(self.dev), y.to(self.dev)\n        with torch.cuda.amp.autocast():\n            loss = self.crit(self.m(x).view(-1, 50257), y.view(-1)) / 16\n        loss.backward()\n        self.acc += 1\n        if self.acc >= 16:\n            nn.utils.clip_grad_norm_(self.m.parameters(), 1.0)\n            # Save gradients BEFORE clearing them!\n            g = self.m.out.weight.grad\n            if g is not None:\n                self.saved_grads = g.clone().cpu()\n            self.opt.step(); self.opt.zero_grad(set_to_none=True); self.acc = 0\n        self.steps += 1\n        l = loss.item() * 16\n        if l < self.best_loss: self.best_loss = l\n        if self.steps % 50 == 0: gc.collect(); torch.cuda.empty_cache()\n        return l\n    \n    def grads(self):\n        # Use saved gradients instead of current (which are None after zero_grad)\n        g = self.saved_grads\n        if g is None: \n            print(\"   âš ï¸ No gradients yet (need more training steps)\")\n            return None\n        gc.collect()\n        flat = g.float().flatten()\n        sample = flat[::10]\n        comp = gzip.compress(sample.half().numpy().tobytes(), 4)\n        return base64.b64encode(comp).decode()\n\nasync def hb(w, tps):\n    try:\n        async with aiohttp.ClientSession() as s:\n            await s.post(f\"{API}/cuda/register\", json={'wallet': w, 'clientVersion': VER, 'deviceInfo': {'gpu_name': 'T4-Colab', 'vram_gb': 15, 'hashrate': tps}})\n    except: pass\n\nasync def submit(w, g, s, l):\n    try:\n        async with aiohttp.ClientSession() as ss:\n            async with ss.post(f\"{API}/cuda/submit\", json={'wallet': w, 'gradients': g, 'epoch': s, 'loss': l, 'gpu': 'T4-Colab'}) as r:\n                if r.status == 200: return (await r.json()).get('reward', 0)\n    except: pass\n    return 0\n\nasync def run():\n    print(\"=\" * 50)\n    print(f\"  ðŸš€ AILO-1B Colab Miner v{VER}\")\n    print(\"=\" * 50)\n    \n    await hb(WALLET, 0)\n    t = Trainer(); t.init(); t.sync_with_global()\n    \n    print(\"\\nâ›ï¸ MINING STARTED!\")\n    print(f\"ðŸ“Š Dashboard: https://ailo.site/dashboard.html?wallet={WALLET[:12]}\\n\")\n    \n    rew, last_s, last_h, tps = 0.0, time.time(), time.time(), 0.0\n    \n    try:\n        while True:\n            t0 = time.time()\n            x, y = t.batch(WALLET)\n            loss = t.step(x, y)\n            tps = 32 / (time.time() - t0 + 0.001)\n            \n            if time.time() - last_h >= 10: await hb(WALLET, tps); last_h = time.time()\n            if t.steps % 25 == 0: print(f\"Step {t.steps} | Loss: {loss:.4f} | Best: {t.best_loss:.4f} | {tps:.0f} tok/s | ðŸ’° {rew:.4f} ALC\")\n            \n            if time.time() - last_s >= 300:\n                print(\"\\nðŸ“¤ Submitting gradients...\")\n                gc.collect(); torch.cuda.empty_cache()\n                g = t.grads()\n                if g:\n                    r = await submit(WALLET, g, t.steps, loss); rew += r\n                    print(f\"ðŸ’° +{r:.4f} ALC (Total: {rew:.4f})\")\n                    if loss < 4.0: t.upload_checkpoint(WALLET, loss, t.steps)\n                else:\n                    print(\"   â­ï¸ Skipping submit (no grads yet)\")\n                t.sync_with_global()\n                last_s = time.time()\n                print()\n                \n    except KeyboardInterrupt: print(f\"\\nâ¹ï¸ Stopped. Total earned: {rew:.4f} ALC\")\n\nawait run()"
            ],
            "metadata": {
                "id": "ailo_miner",
                "cellView": "form"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}