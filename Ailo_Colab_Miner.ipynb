{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üöÄ Ailo Colab Miner (AILO-1B)\n\n**Mine AiloCoin with Google Colab's free T4 GPU!**\n\n1. Runtime > Change runtime type > T4 GPU\n2. Enter wallet below\n3. Runtime > Run all\n\n‚ú® **v1.6.1**: Fixed gradient sync + checkpoint download!"
            ],
            "metadata": {
                "id": "h"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ‚öôÔ∏è 1. Setup\n!pip install torch --index-url https://download.pytorch.org/whl/cu118 -q\n!pip install aiohttp requests -q\nimport gc; gc.collect()\nimport torch\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)} | VRAM: {torch.cuda.get_device_properties(0).total_memory/1e9:.1f}GB\")\nelse:\n    print(\"‚ùå Enable GPU: Runtime > Change runtime type > T4\")"
            ],
            "metadata": {
                "id": "s"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üîë 2. Wallet\nWALLET = \"\"  #@param {type:\"string\"}\nprint(f\"‚úÖ {WALLET[:12]}...\" if len(WALLET)>=40 else \"‚ùå Enter wallet from https://ailo.site/wallet.html\")"
            ],
            "metadata": {
                "id": "w"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üß† 3. AILO-1B Model + Checkpoint Sync\nimport torch, torch.nn as nn, numpy as np, requests, aiohttp, asyncio, time, base64, gzip, gc, os\n\nAPI=\"https://ailo.site/api\"\nSERVER=\"https://ailo.site\"\nVER=\"1.6.1-colab\"\n\nclass AILO1B(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.emb=nn.Embedding(50257,1600)\n        self.pos=nn.Parameter(torch.zeros(1,512,1600))\n        self.tf=nn.TransformerEncoder(nn.TransformerEncoderLayer(1600,25,6400,0.1,batch_first=True),24)\n        self.out=nn.Linear(1600,50257)\n    def forward(self,x):\n        return self.out(self.tf(self.emb(x)*40+self.pos[:,:x.size(1)]))\n\nclass Trainer:\n    def __init__(self):\n        self.dev=torch.device('cuda')\n        self.m=None; self.opt=None; self.steps=0; self.acc=0\n        self.best_loss=float('inf'); self.local_version=0\n    \n    def init(self):\n        print(\"üß† Loading AILO-1B...\")\n        gc.collect(); torch.cuda.empty_cache()\n        self.m=AILO1B().half().to(self.dev)\n        print(f\"   {sum(p.numel() for p in self.m.parameters()):,} params | GPU: {torch.cuda.memory_allocated()/1e9:.1f}GB\")\n        self.opt=torch.optim.SGD(self.m.parameters(),lr=0.001,momentum=0.9)\n        self.crit=nn.CrossEntropyLoss()\n        print(\"   ‚úÖ Ready!\")\n    \n    def sync_with_global(self):\n        \"\"\"Download trained checkpoint or gradients from network.\"\"\"\n        try:\n            print(\"üîÑ Checking for global model...\")\n            r=requests.get(f\"{SERVER}/api/model/weights\",timeout=30)\n            if r.status_code!=200:\n                print(\"   No global model yet\")\n                return False\n            \n            data=r.json()\n            \n            # Try checkpoint first\n            if data.get('hasCheckpoint',False):\n                print(f\"   üì• Downloading checkpoint (loss: {data.get('bestCheckpointLoss','N/A')})...\")\n                cr=requests.get(f\"{SERVER}/api/model/checkpoint\",timeout=60)\n                if cr.status_code==200:\n                    self._load_checkpoint(cr.content)\n                    print(f\"   ‚úÖ Loaded checkpoint from {data.get('checkpointWallet','unknown')}\")\n                    return True\n            \n            # Fallback to gradients\n            sv=data.get('version',0)\n            if sv<=self.local_version:\n                print(f\"   Already at v{self.local_version}\")\n                return True\n            \n            if data.get('downloadUrls',{}).get('gradients'):\n                print(f\"   üì• Downloading gradients v{sv}...\")\n                gr=requests.get(f\"{SERVER}{data['downloadUrls']['gradients']}\",timeout=60)\n                if gr.status_code==200:\n                    self._apply_gradients(gr.content)\n                    self.local_version=sv\n                    print(f\"   ‚úÖ Synced to v{sv}\")\n                    return True\n            return False\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è Sync failed: {e}\")\n            return False\n    \n    def _load_checkpoint(self, data):\n        \"\"\"Load weights into fc_out layer.\"\"\"\n        try:\n            w=np.frombuffer(data,dtype=np.float16).astype(np.float32)\n            print(f\"   Received {len(w):,} weights\")\n            with torch.no_grad():\n                exp=self.m.out.weight.numel()\n                if len(w)>=exp:\n                    t=torch.from_numpy(w[:exp]).reshape_as(self.m.out.weight)\n                    self.m.out.weight.data=t.half().to(self.dev)\n                    print(f\"   ‚úÖ Loaded {exp:,} weights into fc_out\")\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è Load failed: {e}\")\n    \n    def _apply_gradients(self, data):\n        \"\"\"Apply gradients to fc_out (handles sampled 1:10).\"\"\"\n        try:\n            g=np.frombuffer(data,dtype=np.float16).astype(np.float32)\n            print(f\"   Received {len(g):,} gradient values\")\n            with torch.no_grad():\n                out=self.m.out\n                full=out.weight.numel()\n                sampled=full//10\n                lr=0.0001\n                if len(g)>=full:\n                    t=torch.from_numpy(g[:full]).reshape_as(out.weight).half().to(self.dev)\n                    out.weight.data-=lr*t\n                    print(f\"   ‚úÖ Applied full gradients\")\n                elif len(g)>=sampled*0.9:\n                    # Sampled 1:10 - apply to every 10th\n                    flat=out.weight.data.flatten()\n                    gt=torch.from_numpy(g).to(flat.device)\n                    for i in range(min(len(g),len(flat)//10)):\n                        flat[i*10]-=lr*gt[i]\n                    out.weight.data=flat.reshape_as(out.weight)\n                    print(f\"   ‚úÖ Applied sampled gradients to {len(g):,} positions\")\n        except Exception as e:\n            print(f\"   ‚ö†Ô∏è Apply failed: {e}\")\n    \n    def upload_checkpoint(self, wallet, loss, epoch):\n        \"\"\"Upload our weights if we have good loss.\"\"\"\n        try:\n            with torch.no_grad():\n                w=self.m.out.weight.data.cpu().half().numpy().tobytes()\n                w64=base64.b64encode(w).decode()\n            r=requests.post(f\"{SERVER}/api/model/checkpoint\",json={\n                'wallet':wallet,'weights':w64,'loss':loss,'epoch':epoch\n            },timeout=60)\n            if r.status_code==200 and r.json().get('success'):\n                print(f\"   üì¶ Checkpoint uploaded (loss: {loss:.4f})\")\n                return True\n        except:pass\n        return False\n    \n    def batch(self,w):\n        try:\n            r=requests.get(f\"{API}/cuda/training-data\",params={'batchSize':1,'wallet':w},timeout=10)\n            if r.ok:\n                t=r.json().get('articles',[''])[0]\n                tk=[ord(c)%50257 for c in t[:33]]\n                tk+=[0]*(33-len(tk))\n                return torch.tensor([tk[:32]]),torch.tensor([tk[1:33]])\n        except:pass\n        return torch.randint(0,50257,(1,32)),torch.randint(0,50257,(1,32))\n    \n    def step(self,x,y):\n        self.m.train()\n        x,y=x.to(self.dev),y.to(self.dev)\n        with torch.cuda.amp.autocast():\n            loss=self.crit(self.m(x).view(-1,50257),y.view(-1))/16\n        loss.backward()\n        self.acc+=1\n        if self.acc>=16:\n            nn.utils.clip_grad_norm_(self.m.parameters(),1.0)\n            self.opt.step(); self.opt.zero_grad(set_to_none=True); self.acc=0\n        self.steps+=1\n        l=loss.item()*16\n        if l<self.best_loss: self.best_loss=l\n        if self.steps%50==0: gc.collect(); torch.cuda.empty_cache()\n        return l\n    \n    def grads(self):\n        g=self.m.out.weight.grad\n        if g is None: return None\n        gc.collect()\n        flat=g.cpu().float().flatten()\n        sample=flat[::10]\n        del flat; gc.collect()\n        comp=gzip.compress(sample.half().numpy().tobytes(),4)\n        del sample; gc.collect()\n        return base64.b64encode(comp).decode()\n\nprint(\"‚úÖ Ready (v1.6.1 with fixed gradient sync)\")"
            ],
            "metadata": {
                "id": "m"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üöÄ 4. Mine!\n\nasync def hb(w,tps):\n    try:\n        async with aiohttp.ClientSession() as s:\n            await s.post(f\"{API}/cuda/register\",json={'wallet':w,'clientVersion':VER,'deviceInfo':{'gpu_name':'T4-Colab','vram_gb':15,'hashrate':tps}})\n            await s.post(f\"{API}/ping\",json={'wallet':w,'status':'training','hashrate':f\"{tps:.0f} Tok/s\"})\n    except:pass\n\nasync def submit(w,g,s,l):\n    try:\n        async with aiohttp.ClientSession() as ss:\n            async with ss.post(f\"{API}/cuda/submit\",json={'wallet':w,'gradients':g,'epoch':s,'loss':l,'gpu':'T4-Colab'}) as r:\n                if r.status==200: return (await r.json()).get('reward',0)\n    except:pass\n    return 0\n\nasync def run():\n    if len(WALLET)<40: print(\"‚ùå Set wallet!\"); return\n    print(\"=\"*50)\n    print(f\"  AILO-1B Colab Miner v{VER}\")\n    print(\"  üîÑ Auto-syncs with trained network model!\")\n    print(\"=\"*50)\n    \n    await hb(WALLET,0)\n    t=Trainer(); t.init()\n    \n    # Download checkpoint/gradients from network\n    t.sync_with_global()\n    \n    print(\"\\n‚õèÔ∏è MINING!\")\n    print(\"üìä Dashboard: https://ailo.site/dashboard.html\\n\")\n    \n    rew,last_s,last_h,tps=0.0,time.time(),time.time(),0.0\n    \n    try:\n        while True:\n            t0=time.time()\n            x,y=t.batch(WALLET)\n            loss=t.step(x,y)\n            tps=32/(time.time()-t0+0.001)\n            \n            if time.time()-last_h>=10: await hb(WALLET,tps); last_h=time.time()\n            if t.steps%25==0: print(f\"Step {t.steps} | Loss: {loss:.4f} | Best: {t.best_loss:.4f} | v{t.local_version} | {tps:.0f} tok/s\")\n            \n            if time.time()-last_s>=300:\n                print(\"\\nüì§ Submitting gradients...\")\n                gc.collect(); torch.cuda.empty_cache()\n                g=t.grads()\n                if g:\n                    r=await submit(WALLET,g,t.steps,loss); rew+=r\n                    print(f\"üí∞ +{r:.4f} ALC (Total: {rew:.4f})\")\n                    if loss<4.0: t.upload_checkpoint(WALLET,loss,t.steps)\n                \n                # Sync every 10 min\n                t.sync_with_global()\n                last_s=time.time()\n                print()\n                \n    except KeyboardInterrupt: print(f\"\\n‚èπÔ∏è Total: {rew:.4f} ALC\")\n\nawait run()"
            ],
            "metadata": {
                "id": "r"
            },
            "execution_count": null,
            "outputs": []
        }
    ]
}