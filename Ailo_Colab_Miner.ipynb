{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# üöÄ Ailo Network - Colab GPU Miner\n",
                "\n",
                "**Mine AiloCoin usando la GPU gratuita di Google Colab!**\n",
                "\n",
                "Questo notebook usa **AILO-1B** - lo stesso modello del CUDA Miner ufficiale.\n",
                "\n",
                "## ‚ö†Ô∏è IMPORTANTE: Prima di iniziare\n",
                "1. Vai su **Runtime > Disconnect and delete runtime**\n",
                "2. Poi **Runtime > Run all** per partire pulito\n",
                "\n",
                "## Requisiti:\n",
                "- Account Ailo Network (https://ailo.site)\n",
                "- GPU T4 abilitata (Runtime > Cambia tipo di runtime > GPU)\n",
                "\n",
                "---"
            ],
            "metadata": {
                "id": "ailo_header"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#@title ‚öôÔ∏è 1. Setup - Installa Dipendenze e Pulisci Memoria\n",
                "\n",
                "# CRITICAL: Clean up any existing GPU memory from previous runs\n",
                "import gc\n",
                "gc.collect()\n",
                "\n",
                "try:\n",
                "    import torch\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.empty_cache()\n",
                "        torch.cuda.reset_peak_memory_stats()\n",
                "        for obj in gc.get_objects():\n",
                "            if torch.is_tensor(obj):\n",
                "                del obj\n",
                "        gc.collect()\n",
                "        torch.cuda.empty_cache()\n",
                "except:\n",
                "    pass\n",
                "\n",
                "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 -q\n",
                "!pip install websockets aiohttp requests numpy tqdm -q\n",
                "\n",
                "import torch\n",
                "import gc\n",
                "\n",
                "gc.collect()\n",
                "if torch.cuda.is_available():\n",
                "    torch.cuda.empty_cache()\n",
                "    torch.cuda.reset_peak_memory_stats()\n",
                "\n",
                "print(f\"‚úÖ PyTorch {torch.__version__}\")\n",
                "print(f\"‚úÖ CUDA disponibile: {torch.cuda.is_available()}\")\n",
                "if torch.cuda.is_available():\n",
                "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
                "    vram = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
                "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
                "    print(f\"‚úÖ VRAM: {vram:.1f} GB (used: {allocated:.2f} GB)\")"
            ],
            "metadata": {
                "id": "setup_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üîë 2. Inserisci il tuo Wallet Address\n",
                "WALLET_ADDRESS = \"\"  #@param {type:\"string\"}\n",
                "\n",
                "if not WALLET_ADDRESS or len(WALLET_ADDRESS) < 40:\n",
                "    print(\"‚ùå Inserisci un wallet address valido!\")\n",
                "    print(\"   Puoi trovarlo su https://ailo.site/wallet.html\")\n",
                "else:\n",
                "    print(f\"‚úÖ Wallet: {WALLET_ADDRESS[:12]}...{WALLET_ADDRESS[-8:]}\")"
            ],
            "metadata": {
                "id": "wallet_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üß† 3. AILO-1B Training Engine\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "import numpy as np\n",
                "import asyncio\n",
                "import websockets\n",
                "import aiohttp\n",
                "import requests\n",
                "import json\n",
                "import time\n",
                "import base64\n",
                "import gzip\n",
                "import gc\n",
                "from datetime import datetime\n",
                "from typing import Optional, Dict, Tuple, List\n",
                "\n",
                "# Configuration\n",
                "SERVER_URL = \"https://ailo.site\"\n",
                "WS_URL = \"wss://ailo.site/ws/cuda\"\n",
                "API_URL = \"https://ailo.site/api\"\n",
                "CLIENT_VERSION = \"1.2.0-colab\"\n",
                "HEARTBEAT_INTERVAL = 10\n",
                "SUBMIT_INTERVAL = 300\n",
                "\n",
                "# T4 Settings - ultra memory efficient\n",
                "DEFAULT_BATCH_SIZE = 1\n",
                "DEFAULT_SEQ_LEN = 32\n",
                "GRADIENT_ACCUMULATION = 16\n",
                "DEFAULT_LEARNING_RATE = 0.001\n",
                "\n",
                "class SimpleTransformer(nn.Module):\n",
                "    def __init__(self, vocab_size=50257, d_model=1600, nhead=25, num_layers=24, dim_feedforward=6400):\n",
                "        super().__init__()\n",
                "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
                "        self.pos_encoding = nn.Parameter(torch.zeros(1, 512, d_model))\n",
                "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=0.1, batch_first=True)\n",
                "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
                "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
                "        self.d_model = d_model\n",
                "    \n",
                "    def forward(self, x):\n",
                "        seq_len = x.size(1)\n",
                "        x = self.embedding(x) * np.sqrt(self.d_model)\n",
                "        x = x + self.pos_encoding[:, :seq_len, :]\n",
                "        x = self.transformer(x)\n",
                "        return self.fc_out(x)\n",
                "\n",
                "class TrainingEngine:\n",
                "    def __init__(self):\n",
                "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "        self.model = None\n",
                "        self.optimizer = None\n",
                "        self.criterion = nn.CrossEntropyLoss()\n",
                "        self.total_steps = 0\n",
                "        self.best_loss = float('inf')\n",
                "        self.tokens_processed = 0\n",
                "        self.accumulated_steps = 0\n",
                "    \n",
                "    def initialize_model(self):\n",
                "        print(\"üß† Initializing AILO-1B model...\")\n",
                "        gc.collect()\n",
                "        if torch.cuda.is_available():\n",
                "            torch.cuda.empty_cache()\n",
                "        \n",
                "        print(\"   üìê Using AILO-1B: 24 layers √ó 1600d\")\n",
                "        self.model = SimpleTransformer().half().to(self.device)\n",
                "        \n",
                "        total_params = sum(p.numel() for p in self.model.parameters())\n",
                "        print(f\"   Parameters: {total_params:,} ({total_params/1e9:.2f}B)\")\n",
                "        \n",
                "        if torch.cuda.is_available():\n",
                "            print(f\"   üíæ Model memory: {torch.cuda.memory_allocated() / 1024**3:.1f} GB\")\n",
                "        \n",
                "        self.optimizer = optim.SGD(self.model.parameters(), lr=DEFAULT_LEARNING_RATE, momentum=0.9, weight_decay=0.01)\n",
                "        print(\"   ‚úÖ Using SGD optimizer (memory efficient)\")\n",
                "        \n",
                "        for name, param in self.model.named_parameters():\n",
                "            if 'weight' in name and param.dim() > 1:\n",
                "                nn.init.xavier_uniform_(param)\n",
                "            elif 'bias' in name:\n",
                "                nn.init.zeros_(param)\n",
                "        \n",
                "        print(f\"   ‚ö° batch={DEFAULT_BATCH_SIZE}, seq={DEFAULT_SEQ_LEN}, accum={GRADIENT_ACCUMULATION}\")\n",
                "        return self.model\n",
                "    \n",
                "    def _fetch_real_data(self, count, wallet):\n",
                "        try:\n",
                "            response = requests.get(f\"{SERVER_URL}/api/cuda/training-data\", params={'batchSize': count, 'wallet': wallet}, headers={'User-Agent': f'AiloMiner/{CLIENT_VERSION}'}, timeout=30)\n",
                "            if response.status_code == 200:\n",
                "                data = response.json()\n",
                "                if data.get('articles'):\n",
                "                    return data['articles']\n",
                "        except:\n",
                "            pass\n",
                "        return [\"Machine learning is AI. Deep learning uses neural networks. Transformers use attention.\"] * count\n",
                "    \n",
                "    def generate_training_batch(self, wallet):\n",
                "        vocab_size = 50257\n",
                "        texts = self._fetch_real_data(DEFAULT_BATCH_SIZE, wallet)\n",
                "        batch_x, batch_y = [], []\n",
                "        for text in texts:\n",
                "            tokens = [ord(c) % vocab_size for c in text[:DEFAULT_SEQ_LEN + 1]]\n",
                "            while len(tokens) < DEFAULT_SEQ_LEN + 1:\n",
                "                tokens.append(0)\n",
                "            batch_x.append(tokens[:DEFAULT_SEQ_LEN])\n",
                "            batch_y.append(tokens[1:DEFAULT_SEQ_LEN + 1])\n",
                "        return torch.tensor(batch_x, dtype=torch.long), torch.tensor(batch_y, dtype=torch.long)\n",
                "    \n",
                "    def train_step(self, batch_x, batch_y):\n",
                "        self.model.train()\n",
                "        batch_x = batch_x.to(self.device)\n",
                "        batch_y = batch_y.to(self.device)\n",
                "        \n",
                "        outputs = self.model(batch_x)\n",
                "        loss = self.criterion(outputs.view(-1, outputs.size(-1)), batch_y.view(-1)) / GRADIENT_ACCUMULATION\n",
                "        loss.backward()\n",
                "        self.accumulated_steps += 1\n",
                "        \n",
                "        if self.accumulated_steps >= GRADIENT_ACCUMULATION:\n",
                "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
                "            self.optimizer.step()\n",
                "            self.optimizer.zero_grad(set_to_none=True)\n",
                "            self.accumulated_steps = 0\n",
                "        \n",
                "        tokens = batch_x.numel()\n",
                "        self.tokens_processed += tokens\n",
                "        self.total_steps += 1\n",
                "        \n",
                "        if self.total_steps % 200 == 0:\n",
                "            torch.cuda.empty_cache()\n",
                "        \n",
                "        return loss.item() * GRADIENT_ACCUMULATION, tokens\n",
                "    \n",
                "    def extract_gradients(self):\n",
                "        return {name: param.grad.clone() for name, param in self.model.named_parameters() if param.grad is not None}\n",
                "    \n",
                "    def compress_gradients(self, gradients):\n",
                "        flat_grads = [gradients[name].cpu().float().flatten() for name in sorted(gradients.keys())]\n",
                "        all_grads = torch.cat(flat_grads).half()\n",
                "        grad_bytes = all_grads.numpy().tobytes()\n",
                "        compressed = gzip.compress(grad_bytes, compresslevel=6)\n",
                "        encoded = base64.b64encode(compressed).decode('utf-8')\n",
                "        print(f\"   Gradients: {len(grad_bytes)/1024/1024:.1f}MB ‚Üí {len(compressed)/1024/1024:.1f}MB\")\n",
                "        return encoded\n",
                "\n",
                "print(\"‚úÖ TrainingEngine AILO-1B (memory optimized)\")"
            ],
            "metadata": {
                "id": "training_engine_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üîÑ 4. Network Client (con registrazione dashboard)\n",
                "\n",
                "class NetworkClient:\n",
                "    def __init__(self, wallet, gpu_info):\n",
                "        self.wallet = wallet\n",
                "        self.gpu_info = gpu_info\n",
                "        self.ws = None\n",
                "        self.connected = False\n",
                "        self.session_id = None\n",
                "    \n",
                "    async def register(self):\n",
                "        \"\"\"Register with server to appear in dashboard.\"\"\"\n",
                "        try:\n",
                "            print(\"üìù Registering with Ailo server...\")\n",
                "            async with aiohttp.ClientSession() as session:\n",
                "                async with session.post(f\"{API_URL}/cuda/register\", json={\n",
                "                    'wallet': self.wallet,\n",
                "                    'clientVersion': CLIENT_VERSION,\n",
                "                    'deviceInfo': {\n",
                "                        'gpu_name': self.gpu_info.get('gpu_name', 'Tesla T4'),\n",
                "                        'vram_gb': self.gpu_info.get('vram_gb', 15),\n",
                "                        'hashrate': 0\n",
                "                    }\n",
                "                }) as resp:\n",
                "                    if resp.status == 200:\n",
                "                        data = await resp.json()\n",
                "                        self.session_id = data.get('sessionId')\n",
                "                        print(f\"‚úÖ Registered! Session: {self.session_id[:20]}...\")\n",
                "                        return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ö†Ô∏è Registration failed: {e}\")\n",
                "        return False\n",
                "    \n",
                "    async def connect(self):\n",
                "        try:\n",
                "            print(f\"üîå Connecting to {WS_URL}...\")\n",
                "            self.ws = await websockets.connect(WS_URL, ping_interval=30, ping_timeout=10)\n",
                "            await self.ws.send(json.dumps({\n",
                "                'type': 'auth', 'wallet': self.wallet, 'version': CLIENT_VERSION,\n",
                "                'gpu': self.gpu_info.get('gpu_name', 'Unknown'),\n",
                "                'vram': self.gpu_info.get('vram_gb', 0)\n",
                "            }))\n",
                "            response = await asyncio.wait_for(self.ws.recv(), timeout=10)\n",
                "            data = json.loads(response)\n",
                "            if data.get('type') == 'auth_success':\n",
                "                self.connected = True\n",
                "                print(f\"‚úÖ WebSocket connected!\")\n",
                "                return True\n",
                "        except Exception as e:\n",
                "            print(f\"‚ö†Ô∏è WebSocket failed: {e}\")\n",
                "        return False\n",
                "    \n",
                "    async def send_heartbeat(self, hashrate, status, epoch, loss):\n",
                "        \"\"\"Send heartbeat via HTTP for dashboard visibility.\"\"\"\n",
                "        try:\n",
                "            # HTTP ping for dashboard\n",
                "            async with aiohttp.ClientSession() as session:\n",
                "                async with session.post(f\"{API_URL}/ping\", json={\n",
                "                    'wallet': self.wallet,\n",
                "                    'status': status,\n",
                "                    'hashrate': f\"{hashrate:.0f} Tok/s\"\n",
                "                }) as resp:\n",
                "                    pass\n",
                "            \n",
                "            # Also update CUDA client stats\n",
                "            async with aiohttp.ClientSession() as session:\n",
                "                async with session.post(f\"{API_URL}/cuda/register\", json={\n",
                "                    'wallet': self.wallet,\n",
                "                    'clientVersion': CLIENT_VERSION,\n",
                "                    'deviceInfo': {\n",
                "                        'gpu_name': self.gpu_info.get('gpu_name', 'Tesla T4'),\n",
                "                        'vram_gb': self.gpu_info.get('vram_gb', 15),\n",
                "                        'hashrate': hashrate\n",
                "                    }\n",
                "                }) as resp:\n",
                "                    pass\n",
                "            \n",
                "            # WebSocket heartbeat if connected\n",
                "            if self.connected and self.ws:\n",
                "                await self.ws.send(json.dumps({\n",
                "                    'type': 'heartbeat', 'wallet': self.wallet,\n",
                "                    'hashrate': hashrate, 'status': status, 'epoch': epoch, 'loss': loss\n",
                "                }))\n",
                "        except:\n",
                "            pass\n",
                "    \n",
                "    async def submit_gradients(self, gradients_b64, epoch, loss, hashrate):\n",
                "        try:\n",
                "            async with aiohttp.ClientSession() as session:\n",
                "                async with session.post(f\"{API_URL}/cuda/submit\", json={\n",
                "                    'wallet': self.wallet,\n",
                "                    'gradients': gradients_b64,\n",
                "                    'epoch': epoch,\n",
                "                    'loss': loss,\n",
                "                    'hashrate': hashrate,\n",
                "                    'gpu': self.gpu_info.get('gpu_name', 'Tesla T4')\n",
                "                }) as resp:\n",
                "                    if resp.status == 200:\n",
                "                        data = await resp.json()\n",
                "                        reward = data.get('reward', 0)\n",
                "                        print(f\"üí∞ Reward: {reward:.4f} ALC (Total: {data.get('totalRewards', 0):.4f} ALC)\")\n",
                "                        return reward\n",
                "                    else:\n",
                "                        print(f\"‚ö†Ô∏è Submit returned {resp.status}\")\n",
                "        except Exception as e:\n",
                "            print(f\"‚ùå Submit failed: {e}\")\n",
                "        return 0\n",
                "\n",
                "print(\"‚úÖ NetworkClient (con registrazione dashboard)\")"
            ],
            "metadata": {
                "id": "network_client_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "#@title üöÄ 5. Avvia il Mining!\n",
                "\n",
                "async def run_mining():\n",
                "    if not WALLET_ADDRESS or len(WALLET_ADDRESS) < 40:\n",
                "        print(\"‚ùå Inserisci wallet address nella cella 2!\")\n",
                "        return\n",
                "    \n",
                "    gc.collect()\n",
                "    torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
                "    \n",
                "    gpu_info = {\n",
                "        'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n",
                "        'vram_gb': torch.cuda.get_device_properties(0).total_memory / 1024**3 if torch.cuda.is_available() else 0\n",
                "    }\n",
                "    \n",
                "    print(\"=\"*50)\n",
                "    print(f\"  Ailo GPU Miner v{CLIENT_VERSION} - AILO-1B\")\n",
                "    print(\"=\"*50)\n",
                "    print(f\"GPU: {gpu_info['gpu_name']} ({gpu_info['vram_gb']:.1f} GB)\")\n",
                "    print(f\"Wallet: {WALLET_ADDRESS[:12]}...{WALLET_ADDRESS[-8:]}\\n\")\n",
                "    \n",
                "    # Initialize network and register FIRST\n",
                "    network = NetworkClient(WALLET_ADDRESS, gpu_info)\n",
                "    await network.register()  # Register to appear in dashboard!\n",
                "    await network.connect()   # Try WebSocket\n",
                "    \n",
                "    # Then initialize model\n",
                "    training = TrainingEngine()\n",
                "    training.initialize_model()\n",
                "    \n",
                "    print(\"\\n‚õèÔ∏è MINING STARTED!\")\n",
                "    print(\"üìä Check dashboard: https://ailo.site/dashboard.html\\n\")\n",
                "    \n",
                "    total_steps, total_tokens, total_rewards = 0, 0, 0.0\n",
                "    start_time = time.time()\n",
                "    last_heartbeat = last_submit = time.time()\n",
                "    current_loss, current_hashrate = 0.0, 0.0\n",
                "    \n",
                "    try:\n",
                "        while True:\n",
                "            step_start = time.time()\n",
                "            \n",
                "            # Heartbeat every HEARTBEAT_INTERVAL seconds\n",
                "            if time.time() - last_heartbeat >= HEARTBEAT_INTERVAL:\n",
                "                await network.send_heartbeat(current_hashrate, 'training', total_steps, current_loss)\n",
                "                last_heartbeat = time.time()\n",
                "            \n",
                "            batch_x, batch_y = training.generate_training_batch(WALLET_ADDRESS)\n",
                "            loss, tokens = training.train_step(batch_x, batch_y)\n",
                "            \n",
                "            total_steps += 1\n",
                "            total_tokens += tokens\n",
                "            current_loss = loss\n",
                "            elapsed = time.time() - step_start\n",
                "            current_hashrate = tokens / elapsed if elapsed > 0 else 0\n",
                "            \n",
                "            if total_steps % 50 == 0:\n",
                "                gpu_mem = torch.cuda.memory_allocated() / 1024**3 if torch.cuda.is_available() else 0\n",
                "                print(f\"Step {total_steps} | Loss: {loss:.4f} | {current_hashrate:.0f} tok/s | GPU: {gpu_mem:.1f}GB\")\n",
                "            \n",
                "            if time.time() - last_submit >= SUBMIT_INTERVAL:\n",
                "                print(\"\\nüì§ Submitting gradients...\")\n",
                "                gradients = training.extract_gradients()\n",
                "                if gradients:\n",
                "                    compressed = training.compress_gradients(gradients)\n",
                "                    reward = await network.submit_gradients(compressed, total_steps, current_loss, current_hashrate)\n",
                "                    total_rewards += reward\n",
                "                last_submit = time.time()\n",
                "                print()\n",
                "                \n",
                "    except KeyboardInterrupt:\n",
                "        print(\"\\n‚èπÔ∏è Stopped\")\n",
                "    except Exception as e:\n",
                "        print(f\"\\n‚ùå Error: {e}\")\n",
                "        import traceback\n",
                "        traceback.print_exc()\n",
                "    finally:\n",
                "        print(f\"\\nüìä SUMMARY: {total_steps} steps, {total_tokens:,} tokens, {total_rewards:.4f} ALC\")\n",
                "\n",
                "await run_mining()"
            ],
            "metadata": {
                "id": "mining_cell"
            },
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "\n",
                "## ‚ö†Ô∏è Se hai errori di memoria:\n",
                "1. **Runtime > Disconnect and delete runtime**\n",
                "2. **Runtime > Run all** per ricominciare pulito\n",
                "\n",
                "## ‚ÑπÔ∏è Info\n",
                "- **Modello**: AILO-1B (~900M params) - FP16\n",
                "- **Optimizer**: SGD (usa meno memoria di AdamW)\n",
                "- **Dashboard**: Vai su https://ailo.site/dashboard.html per vedere il tuo miner!\n",
                "\n",
                "## üîó Links\n",
                "- [Ailo Network](https://ailo.site)\n",
                "- [Dashboard](https://ailo.site/dashboard.html)\n",
                "- [Wallet](https://ailo.site/wallet.html)\n",
                "\n",
                "---\n",
                "*Ailo Network - Decentralized AI Training*"
            ],
            "metadata": {
                "id": "footer_cell"
            }
        }
    ]
}